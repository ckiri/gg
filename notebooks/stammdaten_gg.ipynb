{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8a4c7976-4f23-4912-8b17-113f3078a482",
   "metadata": {},
   "source": [
    "# Stammdatenanalyse (Gefahrengut)\n",
    "\n",
    "In diesem Notebook wird das Gefahrengut in den Stammdaten analysiert. Dabei werden nur Spalten des Gefahrenguts berücksichtigt."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f86a006-12d9-4d2e-ab7f-09979b726619",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "deb3fd70-3d84-4af1-aa4a-deeaf1b014a7",
   "metadata": {},
   "source": [
    "## Einrichtung\n",
    "\n",
    "In diesem Schritt werden benötigte Module installiert und die notwendigen Daten für unsere Analyse geladen"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64ae7557-1792-4c78-9d4e-9aa973cc055a",
   "metadata": {},
   "source": [
    "### Installieren der Module\n",
    "\n",
    "Installieren der Python-Abhänigkeiten (falls noch nicht durchgeführt):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "046ce09c-c0f5-485e-a42b-725848013dea",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -r ../requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "690bb0b1-82cf-4a09-8a6a-756769cb5b76",
   "metadata": {},
   "source": [
    "Hinzufügen benötigter Python Module:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "626dd01e-7052-404a-83da-71d55e6a03d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os # Operating System utilities (Path manipulation, ...)\n",
    "import requests # For GET requests, used to download the un-number list from wikipedia\n",
    "import pandas as pd # Pandas, work with tables as dataframes (xlsx, csv...)\n",
    "import re # Regular expressions, used in designation analysis\n",
    "import openpyxl # For saving and writing to xlsx files while preserving original formatting\n",
    "import matplotlib.pyplot as plt # Plotting of graphs\n",
    "\n",
    "from collections import Counter # \n",
    "from dotenv import load_dotenv, dotenv_values # Used to load environment variables\n",
    "from rapidfuzz.fuzz import partial_ratio # Fuzzy algorithm (used in desgination analysis)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0793f270-b0ec-4b38-a8af-98bc7e9da001",
   "metadata": {},
   "source": [
    "Laden der Umgebungsvariablen:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7ebe480-e330-4603-8281-f95c5545b9ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "data_path = os.getenv(\"DATA_PATH\")\n",
    "root_path = os.getenv(\"ROOT_PATH\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cf663e7-c02d-4aae-80d4-9375bf1f779d",
   "metadata": {},
   "source": [
    "### Laden der UN-Nummer Liste\n",
    "\n",
    "Als Datenbasis wird die UN-Nummer Liste von [Wikipedia](https://de.wikipedia.org/wiki/Liste_der_UN-Nummern) verwendet. Es sei hierbei noch zu erwähnen, dass\n",
    "es hierfür auch Datenbanken und Tabellen gibt (teilweise Gebührenpflichtig). Die Liste auf Wikipedia\n",
    "kann aber mit wenig aufwand in **Pandas** verwendet werden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7052884-0878-4f3d-b8b5-5c9f2b62f1be",
   "metadata": {},
   "outputs": [],
   "source": [
    "un_numbers_html_path = os.path.join(data_path, 'un_numbers_wikipedia.html')\n",
    "\n",
    "if not os.path.exists(un_numbers_html_path):\n",
    "    try:\n",
    "        print(\"Downloading UN number table from Wikipedia...\")\n",
    "\n",
    "        response = requests.get(\"https://de.wikipedia.org/wiki/Liste_der_UN-Nummern\")\n",
    "        response.raise_for_status()  # Raise error if download failed\n",
    "\n",
    "        # Save to file\n",
    "        with open(un_numbers_html_path, \"w\", encoding=\"utf-8\") as f:\n",
    "            f.write(response.text)\n",
    "\n",
    "        print(f\"Saved HTML to {un_numbers_html_path}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to fetch and save the HTML page: {e}\")\n",
    "\n",
    "un_numbers_tables = pd.read_html(un_numbers_html_path)\n",
    "un_numbers_df = pd.concat(un_numbers_tables).reset_index(drop=True)\n",
    "un_numbers_designation_col = un_numbers_df['Bezeichnung']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9710212-a96e-4285-afea-2c395fe16882",
   "metadata": {},
   "source": [
    "Dataframe als Tabelle darstellen (`#` entfernen):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "539de5e1-cee3-4ed6-8c3d-36b9771ca9b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#un_numbers_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd78b69d-caca-4869-8ad1-f58d8b40284f",
   "metadata": {},
   "source": [
    "### Laden der Stammdaten\n",
    "\n",
    "Die Stammdaten liegen in Form eines Excel Dokuments vor und enthalten verschiedene Fehler, die es gilt zu erkennen\n",
    "und zu behben. Diese Tabelle bildet unsere Datenbasis und wird in den einzelnen Schritten genauer analysiert.\n",
    "\n",
    "Der folgende Prozess lädt das Excel Dokument in einen Dataframe. Mit diesem können die Daten effizienter bearbeitet werden.\n",
    "Durch das beachtliche Größe der Tabelle kann dies je nach Hardware einen kurzen Moment dauern.\n",
    "\n",
    "Es sei hier auch noch erwähnt, dass die ersten Zeilen der Tabelle nicht relevant für die Analyse sind.\n",
    "Es handelt sich hier um Header die zum Zweck der Übersichtlichkeit vorhanden sind. Diese Ignorieren wir daher."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dbf07ee-f37d-43bc-a3ba-a0591cb0aaf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "masterdata_path = os.path.join(data_path, 'stammdaten.xlsx')\n",
    "\n",
    "# openpyxl allows to preserve the original formating, which later comes in handy when writing the changes to a file\n",
    "wb = openpyxl.load_workbook(masterdata_path)\n",
    "ws = wb['Tabelle1']  # The table 'tab' in Excel\n",
    "\n",
    "# As mentioned: Data starts at row 4, so cells 1-3 can be cleaned\n",
    "for row in ws.iter_rows(min_row=4, max_row=ws.max_row):\n",
    "    for cell in row:\n",
    "        cell.value = None\n",
    "\n",
    "full_df = pd.read_excel(masterdata_path, header=None)\n",
    "# Just load necessary data to the dataframe starting at the 3rd row\n",
    "skipped_info = full_df.iloc[:2]\n",
    "masterdata_df = full_df.iloc[2:]\n",
    "masterdata_df.columns = masterdata_df.iloc[0]  # Use the first data row as header aka. col discriptors 'Material-Bezeichnung'\n",
    "masterdata_df = masterdata_df[1:].reset_index(drop=True)\n",
    "masterdata_designation_col = masterdata_df['Material-Bezeichnung']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d6c9b5a-f6b8-4825-ae2f-486e718cfedf",
   "metadata": {},
   "source": [
    "Dataframe als Tabelle darstellen (`#` entfernen):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18c62c01-55ba-4d49-90f5-3df308781bf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#masterdata_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e7176cb-ec7f-40a7-a403-eca13c5f97a5",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c034abd-aad4-498d-bd0c-1f02b120565d",
   "metadata": {},
   "source": [
    "## Bezeichnungsanalyse\n",
    "\n",
    "In der Bezeichnungsanalyse wird die Spalte **'Material-Bezeichnung'** der Stammdaten betrachtet. Hier soll anhand der Bezeichnung\n",
    "untersucht werden ob ein Gefahrengut vorliegt oder nicht. Dabei werden Schlüsselwörter der Stammdaten mit Schlüsselwörtern den \n",
    "Bezeichnungen der UN-Nummer Liste verglichen. Hierbei handelt es sich um einen explorativen Ansatz."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ba6a0ae-e22c-4fb7-a387-94b33008e6b8",
   "metadata": {},
   "source": [
    "### Analyse der Bezeichnungsfelder\n",
    "\n",
    "In dieser Analyse sollen semantische Beziehungen von Feldern der **'Material-Bezeichnung'** in den\n",
    "Stammdaten mit den Bezeichnern der UN-Nummern hergestellt werden.\n",
    "\n",
    "Durch das Erstellen der Beziehungen können dann Materialien der Modulgruppen den UN-Nummern zugeordnet werden.\n",
    "\n",
    "Hierbei sei allerdings erwähnt das Materialbezeichner nicht 100%-tig auf die Bezeichnungen der UN-Nummern\n",
    "zugeordnet werden können. Außerdem kann durch diese Methode auch nicht der Kontext betrachtet werden.\n",
    "\n",
    "Für ein effizienteres Verarbeiten der Daten ist es notwendig ein gewisses Grundrauschen zu entfernen.\n",
    "Mit Grundrauschen sind vorallem Bindewörter gemeint die sich in den Bezeichnungsfelder beider\n",
    "Tabellen befinden.\n",
    "\n",
    "Hiefür werden zuerst die häufigkeit der verwendeter Wörter ermittelt:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f4e1292-941b-402d-b49a-0ac374802e80",
   "metadata": {},
   "outputs": [],
   "source": [
    "masterdata_designation_words = []\n",
    "un_numbers_designation_words = []\n",
    "\n",
    "# Normalization function for a single text entry\n",
    "def normalize_text(text):\n",
    "    if pd.isna(text):\n",
    "        return []\n",
    "    cleaned = (\n",
    "        text.lower()\n",
    "        .replace('ae', 'ä')\n",
    "        .replace('oe', 'ö')\n",
    "        .replace('ue', 'ü')\n",
    "        .replace('.', '')\n",
    "        .replace(',', '')\n",
    "    )\n",
    "    return cleaned.split()\n",
    "\n",
    "def plot_wc(title, all_words):\n",
    "    # Count word frequencies\n",
    "    word_counts = Counter(all_words)\n",
    "    top_n = 50\n",
    "    top_words = word_counts.most_common(top_n)\n",
    "    words, counts = zip(*top_words) # Prepare words for plotting\n",
    "    # Plotting\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.bar(words, counts, color='steelblue')\n",
    "    plt.xticks(rotation=45, ha='right')\n",
    "    plt.ylabel(\"Häufigkeit\")\n",
    "    plt.title(f\"Die {top_n} häufigsten Wörter in {title}\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Apply normalization and collect words\n",
    "masterdata_designation_words.extend(\n",
    "    masterdata_designation_col\n",
    "        .dropna()\n",
    "        .apply(normalize_text)\n",
    "        .explode()\n",
    ")\n",
    "\n",
    "un_numbers_designation_words.extend(\n",
    "    un_numbers_designation_col\n",
    "        .dropna()\n",
    "        .apply(normalize_text)\n",
    "        .explode()\n",
    ")\n",
    "\n",
    "plot_wc(\"Stammdaten\", masterdata_designation_words)\n",
    "plot_wc(\"UN-Nummern\", un_numbers_designation_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d0c02ac-81e9-4055-9f1a-2d8e6db00f34",
   "metadata": {},
   "source": [
    "### Bezeichnungsbereinigung\n",
    "\n",
    "In diesem Schritt werden Worte herausgefiltert die für die Beziehung der beiden Bezeichnungsfeldern keine bedeutung haben.\n",
    "Hierzu wurde manuell eine Liste an sogenannten `stop_words` definiert.\n",
    "\n",
    "Ist die Filterung abgeschlossen erhält man Listen von Keywords der Bezeichnungsfelder jeder Tabelle (`un_keywords_col`& `maserdata_keywords_col`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dabd85d5-adac-43bb-aaf5-5a3890bdf3c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = {\n",
    "    'und', 'mit', 'für', 'von', 'der', 'die', 'das', 'ein', 'eine',\n",
    "    'in', 'an', 'auf', 'im', 'dem', 'des', 'zu', 'am', 'aus', 'kopf',\n",
    "    'vst', 'stg', 'nag', 'oder', 'auch', 'ist', 'als', 'auch',\n",
    "    'nicht', 'einer', 'klassen', 'anderen', 'über', 'einem', 'sind',\n",
    "    'offen', 'sonstigen', 'sonstiges', 'einschließlich', 'zugesetzt',\n",
    "    'enthalten', 'mit', 'ohne', 'als', '°C', '%', 'masse-%', 'typ',\n",
    "    'r', 'gegenstände', 'zerleger', 'vst', 'li', 're', 'stg', 'halter',\n",
    "    'mbn', 'vo', 'ece', 'ob', 'au', 'mi', 'row', 'f', 'fertige', 'frei',\n",
    "    'höchstens', 'stoffe', 'stoffen', 'zündtemperatur', 'anderweitig',\n",
    "    'aufgeführt', 'ausstoß-', 'zuordnen', 'zuzuordnen', 'weniger',\n",
    "    'all', 'hand', 'ext', 'season', 'headunit', 'verstk', 'abdeckung',\n",
    "    'hinweisschild', 'batteriemgmt', 'a-mid', 'asien', 'rohrleitung',\n",
    "    'reifen', 'unter', 'zur', 'mehr', 'twn', 'isr', 'amg'\n",
    "}\n",
    "\n",
    "def sanitize_text(text):\n",
    "    if not isinstance(text, str):\n",
    "        return set()  # or return \"\" if you want string back\n",
    "        \n",
    "    text = (\n",
    "        text.lower()\n",
    "        .replace('ae', 'ä')\n",
    "        .replace('oe', 'ö')\n",
    "        .replace('ue', 'ü')\n",
    "        .replace('li-ion', 'lithium-ionen')\n",
    "        .replace('bat.', 'batterie')\n",
    "        .replace('.', '')\n",
    "        .replace(',', '')\n",
    "        .replace('(', '')\n",
    "        .replace(')', '')\n",
    "    )\n",
    "\n",
    "    #TODO: cleanup abrv. consisting of letters and dots: e.g., z.B., n.a.g.\n",
    "    #text = re.sub(r'\\b(?:[a-zA-Z]\\.){2,}', '', text)\n",
    "\n",
    "    #TODO: remove ',' '.' from words \"fest,\" -> \"fest\"\n",
    "    #text = re.sub(r'[.,]', '', text)\n",
    "\n",
    "    words = set(text.split())\n",
    "    cleaned_words = {\n",
    "        word for word in words\n",
    "        if word not in stop_words\n",
    "        and not re.search(r'\\d', word)  # remove digits from words\n",
    "        and len(word) >= 3\n",
    "    }\n",
    "\n",
    "    return cleaned_words\n",
    "\n",
    "masterdata_keywords_col = masterdata_designation_col.apply(sanitize_text)\n",
    "un_keywords_col = un_numbers_designation_col.apply(sanitize_text)\n",
    "\n",
    "plot_wc(\"Stammdaten Schhlüsselwortliste\", masterdata_keywords_col.explode())\n",
    "plot_wc(\"UN-Nummer Schlüsselwortliste\", un_keywords_col.explode())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c7da2d9-ce9c-42db-bdbb-c733e3d6aff6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#masterdata_keywords_col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd598832-1f91-4f40-bd6b-cc71cd18978d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#un_keywords_col"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb54dd34-4a18-4fd8-b7a8-ce96d7736edb",
   "metadata": {},
   "source": [
    "### Erstellen der Beziehung\n",
    "\n",
    "Durch das Vergleichen jedes einzelnen Schlüsselworts aus der **'Material-Bezeichnung'** mit allen Schlüsselwörtern\n",
    "der UN-Nummern Bezeichnung kann festgestellt werden welche Zeilen welchen der UN-Nummern Liste ähneln.\n",
    "\n",
    "Bei diesem Verfahren wird $m \\times n$ angewendet. Es ergbit sich daher eine schlechte Laufzeitkomplexität.\n",
    "\n",
    "Was zusätzlich die effizienz beinträchtigt ist der verwendete Fuzzy-Algorithmus der gleiche Substrings der Schlüsselwörter Ermittelt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61f697f2-5db3-457d-b997-5abee2ff3d01",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_keyword_matches(masterdata_keywords_col, un_keywords_col):\n",
    "    match_data = []\n",
    "\n",
    "    for master_idx, master_words in masterdata_keywords_col.items():\n",
    "        matched_un_indices = set()\n",
    "        matched_words = set()\n",
    "\n",
    "        for un_idx, un_words in un_keywords_col.items():\n",
    "            local_match = set()\n",
    "\n",
    "            for mw in master_words:\n",
    "                for uw in un_words:\n",
    "                    if len(mw) >= 4 and len(uw) >= 4 and (mw in uw or uw in mw):\n",
    "                        local_match.add(f\"{mw} <-> {uw}\")\n",
    "                    elif partial_ratio(mw, uw) > 85:\n",
    "                        local_match.add(f\"{mw} <~> {uw}\")\n",
    "\n",
    "            if local_match:\n",
    "                matched_un_indices.add(un_idx)\n",
    "                matched_words.update(local_match)\n",
    "\n",
    "        if matched_un_indices:\n",
    "            match_data.append({\n",
    "                \"master_idx\": master_idx,\n",
    "                \"un_indices\": sorted(matched_un_indices),\n",
    "                \"master_keywords\": \", \".join(sorted(master_words)),\n",
    "                \"matched_words\": \", \".join(sorted(matched_words))\n",
    "            })\n",
    "\n",
    "    return pd.DataFrame(match_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1622256-8823-4579-8d9a-c15170422a73",
   "metadata": {},
   "source": [
    "<div style=\"border: 1px solid #1976D2; padding: 10px; border-radius: 5px; background-color: #E8F1FA; margin-right: 100px; margin-left: 100px;\">\n",
    "    <strong>ℹ️ Info:</strong> Vorgang kann etwas dauern! Zum starten <code>#</code> entfernen.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7d275f8-da0d-4154-bf52-b714b1d3d8c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#matches_df = find_keyword_matches(masterdata_keywords_col, un_keywords_col)\n",
    "#matches_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e52a26cb-443b-4a9d-898c-dc434c5d0156",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28597e64-b6a6-42f1-a474-e1aca5d011a5",
   "metadata": {},
   "source": [
    "## Fehlererkennung & Behebung\n",
    "\n",
    "In diesem Abschnitt sollen Unregelmäßigkeiten in den Stammdaten erkannt & behoben werden"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e76df63-40b2-4fe0-8ee0-3f76e69bc782",
   "metadata": {},
   "source": [
    "### Erkennenung von Unregelmäßigkeiten\n",
    "\n",
    "Es sollen nun Unregelmäßigkeiten beim Gefahrengut erkannt werden. Dabei werden nur die für das Gefahrengut relevanten Spalten betrachtet.\n",
    "\n",
    "Hierfür schauen wir uns zuerst an ob in der Spalte **'Art_IdentNr'** ob der Wert `UN` gesetzt ist.\n",
    "Ist dies der Fall, nehmen wir aus der Spalte **'Material-Bezeichnung'** der gleichen Zeile das erste Wort.\n",
    "\n",
    "Mit diesem Wort werden alle nachträglichen Reihen der **'Material-Bezeichnung'** die mit dem gleichen Wort beginnen, durchsucht.\n",
    "Ist hierbei die Spalte **'Art_IdentNr'** nicht mit dem Wert `UN` gesetzt so haben wir eine Unregelmäßigkeit festgestellt.\n",
    "\n",
    "Dieses Verfahren wird mithilfe von Masken umgesetzt bei denen gesetzte und ungesetzt Zeilen der Spalte **'Art_IdentNr'** verundet werden.\n",
    "\n",
    "Die Zeilen der Gruppen bei denen Unregelmäßigkeiten vorkommen werden dargestellt. Bei Korrektheit sind die Zeilen grün gefärbt.\n",
    "Zeilen in denen eine mögliche Diskrepanz vorliegt sind rot gefärbt.\n",
    "\n",
    "Hierbei haben wir die Annahme getroffen, dass die Daten mit ausgefüllter **'Art_IdentNr'** korrekt ausgefüllt wurden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5397af6e-8796-4609-8fde-c73f199ae560",
   "metadata": {},
   "outputs": [],
   "source": [
    "masterdata_df['Art_IdentNr'] = masterdata_df['Art_IdentNr'].astype(str)\n",
    "masterdata_df['1. Teilwort'] = masterdata_df['Material-Bezeichnung'].str.split().str[0]\n",
    "\n",
    "grouped = masterdata_df.groupby('1. Teilwort')\n",
    "rows = []\n",
    "inconsistent_first_words = []\n",
    "\n",
    "for first_word, group in grouped:\n",
    "    un_mask = group['Art_IdentNr'] == 'UN'\n",
    "    non_un_mask = group['Art_IdentNr'] != 'UN'\n",
    "\n",
    "    has_un = un_mask.any()\n",
    "    has_non_un = non_un_mask.any()\n",
    "\n",
    "    # Only collect groups where both 'UN' and non-'UN' exist (inconsistent)\n",
    "    if has_un and has_non_un:\n",
    "        inconsistent_first_words.append(first_word)\n",
    "        for idx, row in group.iterrows():\n",
    "            is_correct = row['Art_IdentNr'] == 'UN'\n",
    "            row_dict = row.to_dict()\n",
    "            row_dict['Korrektheit'] = is_correct\n",
    "            row_dict['Ursprungsindex'] = idx  # Keep old line numbers (even though not displayed)\n",
    "            rows.append(row_dict)\n",
    "def highlight_correct(row):\n",
    "    styles = [''] * len(row)\n",
    "    if row['Korrektheit']:\n",
    "        # Find index of 'Bezeichnung' column and color only that cell\n",
    "        col_idx = row.index.get_loc('Korrektheit')\n",
    "        styles[col_idx] = 'background-color: #478523; color: #FFFFFF'\n",
    "    else:\n",
    "        col_idx = row.index.get_loc('Korrektheit')\n",
    "        styles[col_idx] = 'background-color: #CE3E69; color: #FFFFFF'\n",
    "    return styles\n",
    "\n",
    "def display_df(vis_df):\n",
    "    display(\n",
    "        vis_df[['1. Teilwort',\n",
    "                'Material-Bezeichnung',\n",
    "                'Art_IdentNr',\n",
    "                'IdentNr',\n",
    "                'Klasse',\n",
    "                'GG_Vorschrift See',\n",
    "                'Verp.Methode See',\n",
    "                'GG_Vorschrift Luft',\n",
    "                'Verp.Methode Luft',\n",
    "                'Korrektheit']]\n",
    "            .style\n",
    "            .apply(highlight_correct, axis=1)\n",
    "            .format({\n",
    "                'IdentNr': '{:.0f}',\n",
    "                'Klasse': '{:.1f}',\n",
    "                'Verp.Methode See': '{:.0f}',\n",
    "                'Verp.Methode Luft': '{:.0f}'\n",
    "            })\n",
    "            .set_table_styles([\n",
    "                {'selector': 'table',\n",
    "                 'props': [('table-layout', 'fixed'), ('width', '100%')]},\n",
    "                {'selector': 'th, td',\n",
    "                 'props': [('overflow', 'hidden'), \n",
    "                       ('text-overflow', 'ellipsis'),\n",
    "                       ('white-space', 'nowrap'),\n",
    "                       ('font-size', '12px')]}  # Adjust font size here\n",
    "            ])\n",
    "            .set_properties(**{\n",
    "                'max-width': '100px',  # Optional: Limit cell width\n",
    "                'white-space': 'normal',  # or 'nowrap'\n",
    "                'font-size': '12px'  # Adjust globally\n",
    "            })\n",
    "        \n",
    "    )\n",
    "\n",
    "vis_df = pd.DataFrame(rows)\n",
    "vis_df = vis_df.sort_values(by=['1. Teilwort', 'Korrektheit'], ascending=[True, False])\n",
    "display_df(vis_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bd4af09-ac80-4bf3-9af5-57abf12ed78f",
   "metadata": {},
   "source": [
    "### Ausfüllen fehlender Werte\n",
    "\n",
    "Die zuvor gefundenen leeren Zeilen können nun mit den Werten aus der gleichen **Wortgruppe** aufgefüllt werden.\n",
    "Eine Wortgruppe wird vom **1. Teilwort** festgelegt und umschließt jedes Materialbezeichnungsfeld welches dieses besitzt.\n",
    "\n",
    "Man sieht, dass die Fehlenden Zeilen mit Werten aus der gemeinsamen Wortgruppe ausgefüllt werden. Das geschieht aber nur \n",
    "unter der Annahme das bereits ausgefüllte Zeilen korrekt ausgefüllt wurden und keine Fehler enthalten."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21abbbf5-55e5-48b6-b79c-b33b27ab7e9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "rows = []\n",
    "\n",
    "for first_word in inconsistent_first_words:\n",
    "    group = grouped.get_group(first_word)\n",
    "\n",
    "    # Find a valid reference row: must be 'UN' and not NaN in the target columns\n",
    "    valid_source_rows = group[\n",
    "        (group['Art_IdentNr'] == 'UN') &\n",
    "        (group['IdentNr'].notna()) &\n",
    "        (group['Klasse'].notna())\n",
    "    ]\n",
    "\n",
    "    if valid_source_rows.empty:\n",
    "        print(f\"No fully populated 'UN' row found for group '{first_word}'\")\n",
    "        continue\n",
    "\n",
    "    # Use the first fully valid row as the source of truth\n",
    "    correct_row = valid_source_rows.iloc[0]\n",
    "    correct_ident = correct_row['IdentNr']\n",
    "    correct_klasse = correct_row['Klasse']\n",
    "    correct_gg_vorschrift_see = correct_row['GG_Vorschrift See']\n",
    "    correct_verp_methode_see = correct_row['Verp.Methode See']\n",
    "    correct_gg_vorschrift_luft = correct_row['GG_Vorschrift Luft']\n",
    "    correct_verp_methode_luft = correct_row['Verp.Methode Luft']\n",
    "\n",
    "    for idx, row in group.iterrows():\n",
    "        row_dict = row.to_dict()\n",
    "        row_dict['Ursprungsindex'] = idx  # Preserve original line number\n",
    "\n",
    "        if row['Art_IdentNr'] != 'UN':\n",
    "            row_dict['Art_IdentNr'] = 'UN'\n",
    "            if pd.isna(row['IdentNr']):\n",
    "                row_dict['IdentNr'] = correct_ident\n",
    "            if pd.isna(row['Klasse']):\n",
    "                row_dict['Klasse'] = correct_klasse\n",
    "            if pd.isna(row['GG_Vorschrift See']):\n",
    "                row_dict['GG_Vorschrift See'] = correct_gg_vorschrift_see\n",
    "            if pd.isna(row['Verp.Methode See']):\n",
    "                row_dict['Verp.Methode See'] = correct_verp_methode_see\n",
    "            if pd.isna(row['GG_Vorschrift Luft']):\n",
    "                row_dict['GG_Vorschrift Luft'] = correct_gg_vorschrift_luft\n",
    "            if pd.isna(row['Verp.Methode Luft']):\n",
    "                row_dict['Verp.Methode Luft'] = correct_verp_methode_luft\n",
    "            row_dict['Korrektheit'] = False\n",
    "        else:\n",
    "            row_dict['Korrektheit'] = True\n",
    "\n",
    "        rows.append(row_dict)\n",
    "\n",
    "vis_df = pd.DataFrame(rows)\n",
    "display_df(vis_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "521fbe32-b5e5-4497-91e6-da15814c1bfa",
   "metadata": {},
   "source": [
    "### Speichern der Korrektur\n",
    "\n",
    "Der letzte Schritt ist es nun die bearbeiteten Daten zurück in eine Tabelle zu schreiben.\n",
    "Hierbei kommt uns zu gute dass wir mit **Openpyxl** alle Formatierungen der Ursprünglichen\n",
    "Tabelle beibehalten haben.\n",
    "\n",
    "Es wird unser Dataframe iterativ in das Worksheet der Tabelle geschrieben."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ae49cef-8ad6-4d3a-b7f9-c8cfedf5e84b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for _, row in vis_df.iterrows():\n",
    "    idx = row['Ursprungsindex']\n",
    "    masterdata_df.loc[idx, 'Art_IdentNr'] = row['Art_IdentNr']\n",
    "    masterdata_df.loc[idx, 'IdentNr'] = row['IdentNr']\n",
    "    masterdata_df.loc[idx, 'Klasse'] = row['Klasse']\n",
    "    masterdata_df.loc[idx, 'GG_Vorschrift See'] = row['GG_Vorschrift See']\n",
    "    masterdata_df.loc[idx, 'Verp.Methode See'] = row['Verp.Methode See']\n",
    "    masterdata_df.loc[idx, 'GG_Vorschrift Luft'] = row['GG_Vorschrift Luft']\n",
    "    masterdata_df.loc[idx, 'Verp.Methode Luft'] = row['Verp.Methode Luft']\n",
    "\n",
    "start_row = 4\n",
    "for i, row in masterdata_df.iterrows():\n",
    "    for j, value in enumerate(row):\n",
    "        ws.cell(row=start_row + i, column=j + 1, value=value)\n",
    "\n",
    "masterdata_path_corrected = os.path.join(data_path, 'stammdaten_korrektur.xlsx')\n",
    "wb.save(masterdata_path_corrected)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
